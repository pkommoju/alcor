= Draft design of GoalState reconciliation
Prasad Kommoju <pkommoju@futurewei.com>
v.01, 2021-05-10
:toc: right
:sectnums:
Reference: https://en.wikipedia.org/wiki/Bloom_filter

== Overview
GoalState is a set of many different pieces of information about the network configuration of a given host. This is called Intent in some literature. It changes with time, mostly because the users have made some modifications. Sometimes, the changes may arise from the hosts themselves (ground truth, in some literature).

The task of establishing a new goal state from the existing state given a set of changes and publishing it to all concerned entities is the focus of GoalState reconciliation.

It would not deserve a document of its own, if it were simple to compute and inexpensive to distribute. At the moment, GoalState has eight different collections, each of them could contain many instances, or sub-collections.

The main idea here is to find a way to quickly decide if two GoalStates, say G1, and G2 are same or not. If they are different, what is the minimum difference, referred to as GoalState Delta (GSD) in this document. The benefit of the first one is obvious. The benefits of the second part are a) savings in distribution cost, b) savings in host memory requirements.

Any design should also keep in mind that the GoalState structure itself might change with time and the design should not break backward compatibility while admitting new changes.

== Goals and requirements of GoalState reconciliation design
Based on the overview, the following can be said to be the critical goals for the design.

* Fast to detect the differences.
* Smallest possible payload to distribute.
* Removing existing properties in GoalStates should not break the functionality.
* Adding new properties should be easy, and should not break the functionality.

The first design will keep these goals in mind but can not deliver the second requirement (Smallest possible payload to distribute), instead the payload size will be made smaller in incremental fashion. The reason is that as the size of the payload gets smaller, the time to detect the differences and compute the GSD will go up. There might be an optimal point of intersection of these two metrics but it can not be guessed at this time.

== General mechanisms to meet the requirements
* Each object or entity that ends up in the GoalState shall have its own unique identifier or an enum (hereafter referred to as EID) within its own "namespace".
* Existing entities GoalState object shall not be removed.
* GoalState object can have new entities but without conflicting with any of the previous entities. This means each new entity gets its own unique identifier, or enum.
* New entities are always added to GoalState after the last entity.
* Recursively, these rules are applied down the hierarchy of entities in the GoalState object.
* A signature will be used to detect the differences, and partitioned GoalState object will be used to compute the smallest GSD.

=== EID
The EID becomes part of the signature of the entity in detecting GSD, therefore EID should not be reused.

=== GoalState object shall not remove existing entities
The existing entities may be made inactive so that they don't occupy any space but their existence will not be removed.

For instance, If SecurityGroupState is deprecated and a new version of it is introduced. This rule requires that SecurityGroupState be left alone and the new version be added after the last entity, with a different name and EID.

The other mechanisms are self explanatory. These mechanisms are used together to create a canonical representation of the GoalState object, and its components recursively. What this means that, if two GoalState objects (or its sub objects) are copies of each other but merely arranged in a different manner, the canonical representation of the two copies will result in the same signature. This is the key technique in finding if two objects are same or not.

The next section explains the mechanism used to detect the smallest difference (GSD) based on the idea of canonical representation.

== The portioned signature method
At the moment, the following entities are part of the GoalState:

* VpcState 
* SubnetState
* PortState
* NeighborState
* SecurityGroupState
* DHCPState
* RouterState
* GatewayState

Each of them can occur more than once. As stated in Section 2 above, the first iteration will focus on finding the smallest GSD for each of these collections.

A pseudo code such below can be used to compute the signatures.
[source,]
----

    Signature[] computeSignature(GoalState obj)
    {
        vpcStateSig = computeEntitySignature(obj.vpcState);
        snsStateSig = computeEntitySignature(obj.subnetState);
        ...
        gwStateSig  = computeEntitySignature(obj.gatewayState);
        
        signatures[] = {EMPTY, vpcStateSig, ..., gwStateSig);
        globalSig = CompositeSignature(signatures);
        signatures[0] = globalSig;
        
        return signatures;
    }
----

computeEntitySignature will descend down the object hierarchy and return a signature for the canonical representation of the input object.

computeSignature will itself return a global signature for the whole GoalState, and the signatures of individual sub-objects of the GoalState.

Given global signature GSIG1 and GSIG2 of GoalStates GS1 and GS2, it is possible to assert if GS1 and GS2 are same are different. if they are same, then there is no need to compute the smallest delta, the GSD.

If GSIG1 and GSIG2 are different, the GSD is the set of all sub-objects in GS1 and GS2 which have a different signature (vpcStateSig, snsStateSig etc.,).


== Idea for a quick prototype

A quick prototype can be brought up using the hashCode() method rather than waiting for adding the signature creation method down the hierarchy. This will still require some new code to be written, but the effort is expected to be smaller than the eventual signature based method. There will have to be a wrapper around hashCode method to handle objects which have sub-objects on so on.

New caches needed:

=== A Cache of GoalState signature which covers the whole of the GoalState.
This will contain the GS signature, and an object containing the GS, along with signatures for all components contained in that GS.

At a high level, the following new classes and cache are needed.

[source,]
----
class VpcSign
{
    String      vpcSign;
    VpcState    vpsState;
}

class SubnetSign
{
    String      snSign;
    SubnetState snState;
}

class PortStateSign
{
    String      ptSign;
    PortState   ptState;
}

class NeighborState
{
    String          nbSign;
    NeighborState   nbState;
}

class SecurityGroupState
{
    String              sgSign;
    SecurityGroupState  sgState;
}

class DHCPState
{
    String      dhSign;
    DHCPState   dhState;
}

class RouterState
{
    String      rtSign;
    RouterState rtState;
}

class GatewayState
{
    String          gwSign;
    GatewayState    gwState;
}

class GoalStateSignatureCache
{
    Map<String /* gsSign */, GoalState> gsSignCache;
    ...
}

----

[source,]
----
// Add a getSignature method to each sub object of GoalState
// and its subobjects.
class GoalState
{
    ...
    // Create Signture for the entire GoalState object
    public Signature getSignature()
    {
        // get Signature of each sub object and fill them
        // into sigs, visitor pattern?
        Signature[] sigs;
        foreach (s : subobjects)
            sigs.append(s.getSignature());
        // visitor pattern?
        Signtaure sig = combineSig(sigs);
        return sig;
    }
    ...
}

// Some leaf class in the hierarchy rooted at GoalState object
class GoalStateLeafClass
{
    ...
    public Signature getSignature()
    {
        Signature sig = data.hashCode();
        return sig;
    }
    ...
}
----

== Alternative designs
Instead of the top down approach described in the previous section, a bottom up approach can be used to build the GSD without the use of signatures.

At the bottom (leaf node object) GS will be simple object containing only atomic values, or a simple object with one or more arrays of atomic values.

There are two alternatives, not mutually exclusive.

=== Hash based method
This is the traditional method. Old Goal State components are hashed into a hash table and the corresponding components from the new Goal state are probed. If a match is not found, that component is added to the GSD. If a match is found, then a value comparison is done to rule out hash collision. 
While this method is fast and accurate, for large objects, it will require proportionally large amount of memory.

=== Bloom filter based method
Bloom filter is a probabilistic data structure which answers the question of "does this element existing in the set" with "Definitely absent" or "Probably present" (False positive). The ratio of false positives can be made smaller by using more memory. The space and time requirements of bloom filter are constant, space dependent only on the ratio of false positives.

There are many variations of bloom filter

At a high level, the following algorithms illustrate using Hash and Bloom methods together.

=== Version based
It seems there is a "version" construct in the GS objects which will be different in two GS if one is a modified version of the other. It is not clear if this construct is present in all sub-objects of GS, and their sub-objects. If in fact, it turns out that, this construct is present in the entire hierarchy of objects rooted in GS, then this will be used to detect if the GS differ since this will be faster than any of the proposed methods.

Computing the actual delta itself will have to use Hash, bloom, or a combination as described in the following sections.

[source,]
----
/**
* Returns the method to use, given two similar (Comparable) Objects.
*/
selectMethod(Obj1, Obj2) {
    if (sizeof(Obj1) > THRESHOLD)
        return BLOOM;
    if (sizeof(Obj2) > THRESHOLD)
        return BLOOM;

    return HASH;
}

bloomDelta(oldSet, newSet) {
    bloom = {};
    delta = {};

    foreach (a in oldSet.arrayOfObj) {
        foreach (e in a) {
            bloom.add(e);
        }
    }

    /**
    * This is done for each member, loop is for
    * brevity.
    */
    foreach (e in oldSet.simpleObj) {
        bloom.add(e);
    }

    foreach (a in newSet.arrayOfObj) {
        foreach (e in a) {
            if (bloom.probe(e) == ABSENT) {
                delta.add(e);
        }
    }

    /**
    * This is done for each member, loop is for
    * brevity.
    */
    foreach (e in oldSet.simpleObj) {
        if (bloom.probe(e) == ABSENT) {
             delta.add(e);
        }
    }

    return delta;
}

hashDelta(oldSet, newSet) {
    hash = {};
    delta = {};

    foreach (a in oldSet.arrayOfObj) {
        foreach (e in a) {
            hash.add(e);
        }
    }

    /**
    * This is done for each member, loop is for
    * brevity.
    */
    foreach (e in oldSet.simpleObj) {
        hash.add(e);
    }

    foreach (a in newSet.arrayOfObj) {
        foreach (e in a) {
            if (bloom.probe(e) == ABSENT) {
                delta.add(e);
        }
    }

    /**
    * This is done for each member, loop is for
    * brevity.
    */
    foreach (e in oldSet.simpleObj) {
        if (bloom.probe(e) == ABSENT) {
             delta.add(e);
        }
    }

    return delta;
}

/**
* Given two comparable objects (oldSet and newSet), find the delta
* as elements in newSet which are not present in oldSet.
*/
computeDelta(oldSet, newSet) {
    if (selectMethod(oldSet, newSet) == BLOOM)
        return bloomDelta(oldSet, newSet);
    else
        return hashDelta(oldSet, newSet);
}
----

All the algorithms shown above may indicate that there is a generic version of each which works on any object but that is not really the case. They will have to be specific (virtual methods) for each type/class which is part of GS in the hierarchy.

=== Handling hash collisions and false positives in bloom method
An obvious omission in the algorithms is the case when a probe finds a match. In hashDelta method, it is easy to compare the values to resolve a possible false positive due to hash collision.

In case of bloomDelta this value comparison is not a possibility because they are not part of the bloom filter.

One solution would be to keep the false positive rate very low, say 0.0001, then the number of false positives will be less than 100 for every million objects. So, in 100 out of 1M cases we may end up pushing or pulling down a full GS.

